import argparse
import easydict
import sys
import os
import time
import yaml
import numpy as np
import torch
import torch.nn as nn
import torch.utils.data as data
import torchvision.transforms as transforms
from tensorboardX import SummaryWriter
# ä¿ç•™å¿…è¦å·¥å…·ï¼Œæ–°å¢CSANetä¸“å±å·¥å…·
from utils import (
    CSANetLogger, AverageMeter, set_seed, GenIdx, CSANetSingleModalitySampler, CSANetCurriculumSampler,
    build_modal_memory, generate_curriculum_mask, get_current_curriculum
)
from data_loader import SYSUData, RegDBData, TestData, get_adca_transform  # å¯¼å…¥è®ºæ–‡ADCAæ•°æ®å¢å¼º
from data_manager import (
    process_query_sysu, process_gallery_sysu, process_test_regdb
)
# æ›¿æ¢æ¨¡å‹ï¼šåˆ é™¤BaseResNetï¼Œå¯¼å…¥CSANetï¼ˆåŸºäºTransReIDï¼‰
from model.network import CSANet
# æ›¿æ¢æŸå¤±ï¼šåˆ é™¤å†—ä½™æŸå¤±ï¼Œå¯¼å…¥CSANetæ€»æŸå¤±è®¡ç®—å™¨
from loss import CSANetTotalLoss
# æ–°å¢æ¨¡å—å†»ç»“åŠŸèƒ½ï¼Œé€‚é…åˆ†é˜¶æ®µè®­ç»ƒ
from optimizer import select_optimizer, adjust_learning_rate, freeze_modules
from engine import trainer, tester  # å¤ç”¨é€‚é…åçš„è®­ç»ƒ/æµ‹è¯•å™¨
from otla_sk import cpu_sk_ir_trainloader, evaluate_pseudo_label  # ä¿ç•™OTLA-SKä¼ªæ ‡ç­¾ä¼˜åŒ–

# -------------------------- CSANetå…¨å±€é…ç½®ï¼ˆä¸¥æ ¼å¯¹é½è®ºæ–‡ï¼‰ --------------------------
CSANET_CONFIG = {
    "train_stage": {
        "step_i_epoch": 20,    # Step-Iå•æ¨¡æ€èšç±»epochæ•°ï¼ˆè®ºæ–‡Algorithm 1 ES1ï¼‰
        "step_ii_epoch": 40,   # Step-IIè·¨æ¨¡æ€å…³è”epochæ•°ï¼ˆES2ï¼‰
        "total_epoch": 60      # æ€»epochï¼ˆ20+40ï¼‰
    },
    "memory": {
        "momentum": 0.9,       # è®°å¿†åº“åŠ¨é‡æ›´æ–°ç³»æ•°ï¼ˆè®ºæ–‡Eq.3ï¼‰
        "update_freq": 5       # è®°å¿†åº“æ›´æ–°é¢‘ç‡ï¼ˆæ¯5 epochï¼‰
    },
    "curriculum": {
        "optimize_courses": ["moderate", "intricate"]  # OTLA-SKä»…ä¼˜åŒ–ä¸­ç­‰/å¤æ‚è¯¾ç¨‹
    }
}

def main_worker(args, args_main):
    ## 1. åŸºç¡€é…ç½®åˆå§‹åŒ–ï¼ˆè®¾å¤‡ã€ç§å­ã€è·¯å¾„ï¼‰
    # GPUä¸ç§å­é…ç½®ï¼ˆç¡®ä¿å®éªŒå¯å¤ç°ï¼Œè®ºæ–‡è¦æ±‚ï¼‰
    os.environ["CUDA_VISIBLE_DEVICES"] = str(args.gpu)
    device = "cuda" if torch.cuda.is_available() else "cpu"
    torch.backends.cudnn.benchmark = args.cudnn_benchmark if hasattr(args, "cudnn_benchmark") else True
    set_seed(args.seed, cuda=torch.cuda.is_available())

    # è·¯å¾„é…ç½®ï¼ˆå…¼å®¹åŸæœ‰é€»è¾‘ï¼Œè¡¥å……è®°å¿†åº“ä¿å­˜è·¯å¾„ï¼‰
    exp_dir = f"{args.dataset}_{args.setting}_{args.file_name}"
    if not os.path.isdir(exp_dir):
        os.makedirs(exp_dir)
    log_path = os.path.join(exp_dir, f"{args.dataset}_{args.log_path}")
    vis_log_path = os.path.join(exp_dir, f"{args.dataset}_{args.vis_log_path}")
    model_path = os.path.join(exp_dir, f"{args.dataset}_{args.model_path}")
    memory_path = os.path.join(exp_dir, "memory")  # æ–°å¢è®°å¿†åº“è·¯å¾„
    for path in [log_path, vis_log_path, model_path, memory_path]:
        if not os.path.isdir(path):
            os.makedirs(path)

    # æ—¥å¿—åˆå§‹åŒ–
    sys.stdout = CSANetLogger(os.path.join(log_path, "train.log"))
    test_log = open(os.path.join(log_path, "test.log"), "w")
    writer = SummaryWriter(vis_log_path)
    print(f"å®éªŒé…ç½®ï¼š\nargs_main: {args_main}\nargs: {args}\n")

    ## 2. æ•°æ®åŠ è½½ï¼ˆé€‚é…è®ºæ–‡ADCAå¢å¼ºä¸åˆ†é˜¶æ®µéœ€æ±‚ï¼‰
    print("==> åŠ è½½æ•°æ®é›†...")
    t_start = time.time()

    # æ•°æ®å¢å¼ºï¼šæ›¿æ¢ä¸ºè®ºæ–‡ADCAç­–ç•¥ï¼ˆé¿å…è¿‡æ‹Ÿåˆï¼Œæå‡æ³›åŒ–æ€§ï¼‰
    transform_train = get_adca_transform(args.img_w, args.img_h, is_train=True)
    transform_test = get_adca_transform(args.img_w, args.img_h, is_train=False)

    # åŠ è½½è®­ç»ƒé›†ï¼ˆåˆ†Step-I/IIï¼ŒStep-Iå•æ¨¡æ€ï¼ŒStep-IIåŒæ¨¡æ€ï¼‰
    train_loaders = {}
    if args.dataset == "sysu":
        data_path = os.path.join(args.dataset_path, "SYSU-MM01/")
        # Step-Iå•æ¨¡æ€è®­ç»ƒé›†ï¼ˆç”¨äºèšç±»ä¸è®°å¿†åº“åˆå§‹åŒ–ï¼‰
    # Step-Iï¼šå¤ç”¨åŸç‰ˆåŒæ¨¡æ€åŠ è½½é€»è¾‘ï¼Œé€šè¿‡é‡‡æ ·å™¨ç­›é€‰å•æ¨¡æ€æ ·æœ¬
    # 1. åŠ è½½åŒæ¨¡æ€è®­ç»ƒé›†ï¼ˆåŸç‰ˆ SYSUData æ—  is_train å‚æ•°ï¼Œè‡ªåŠ¨é€šè¿‡ pre_process_sysu åŠ è½½è®­ç»ƒæ•°æ®ï¼‰
        trainset_step1 = SYSUData(
            args, data_path,
            transform_train_rgb=transform_train,  # å¯è§å…‰å¢å¼º
            transform_train_ir=transform_train   # çº¢å¤–å¢å¼ºï¼ˆStep-Iæš‚ç”¨åŒä¸€å¢å¼ºï¼‰
        )

        # 2. Step-Iå•æ¨¡æ€é‡‡æ ·å™¨ï¼ˆä»…é‡‡æ ·å¯è§å…‰æ ·æœ¬ï¼Œæ— éœ€æ–°å¢ current_modalï¼‰
        vis_sampler = CSANetSingleModalitySampler(
            modal_pseudo_label=trainset_step1.train_color_label,  # å¯è§å…‰æ ‡ç­¾
            num_pos=args.num_pos,
            batch_size=args.train_batch_size
        )
        # 3. ç”Ÿæˆå•æ¨¡æ€è®­ç»ƒåŠ è½½å™¨ï¼ˆä»…åŠ è½½å¯è§å…‰æ ·æœ¬ï¼‰
        trainset_step1.cIndex = vis_sampler.index1  # å¯è§å…‰æ ·æœ¬ç´¢å¼•
        trainset_step1.tIndex = vis_sampler.index1  # çº¢å¤–ç´¢å¼•æš‚ç”¨å¯è§å…‰ï¼ˆStep-Iä»…ç”¨å¯è§å…‰ï¼‰
        trainloader_vis = data.DataLoader(
            trainset_step1, batch_size=args.train_batch_size * args.num_pos,
            sampler=vis_sampler, num_workers=args.workers, drop_last=True
        )
        trainset_step1_ir = SYSUData(
            args, data_path, transform_train=transform_train,
            is_train=True, for_memory=True, current_modal="ir"
        )
        train_loaders["step_i_vis"] = data.DataLoader(
            trainset_step1_vis, batch_size=args.test_batch_size,
            shuffle=False, num_workers=args.workers
        )
        train_loaders["step_i_ir"] = data.DataLoader(
            trainset_step1_ir, batch_size=args.test_batch_size,
            shuffle=False, num_workers=args.workers
        )

        # Step-IIåŒæ¨¡æ€è®­ç»ƒé›†ï¼ˆç”¨äºè·¨æ¨¡æ€å…³è”å­¦ä¹ ï¼‰
        trainset_step2 = SYSUData(
            args, data_path, transform_train_rgb=transform_train,
            transform_train_ir=transform_train, is_train=True
        )

        # æµ‹è¯•é›†ï¼ˆæŒ‰è®ºæ–‡åè®®å¤„ç†ï¼Œä¿ç•™ç›¸æœºIDç”¨äºè¯„ä¼°ï¼‰
        query_img, query_label, query_cam = process_query_sysu(data_path, mode=args.mode)
        gall_img, gall_label, gall_cam = process_gallery_sysu(data_path, mode=args.mode)

    elif args.dataset == "regdb":
        data_path = os.path.join(args.dataset_path, "RegDB/")
        # Step-Iå•æ¨¡æ€è®­ç»ƒé›†
        trainset_step1_vis = RegDBData(
            args, data_path, transform_train=transform_train,
            is_train=True, for_memory=True, current_modal="vis"
        )
        trainset_step1_ir = RegDBData(
            args, data_path, transform_train=transform_train,
            is_train=True, for_memory=True, current_modal="ir"
        )
        train_loaders["step_i_vis"] = data.DataLoader(
            trainset_step1_vis, batch_size=args.test_batch_size,
            shuffle=False, num_workers=args.workers
        )
        train_loaders["step_i_ir"] = data.DataLoader(
            trainset_step1_ir, batch_size=args.test_batch_size,
            shuffle=False, num_workers=args.workers
        )

        # Step-IIåŒæ¨¡æ€è®­ç»ƒé›†
        trainset_step2 = RegDBData(
            args, data_path, transform_train_rgb=transform_train,
            transform_train_ir=transform_train, is_train=True
        )

        # æµ‹è¯•é›†ï¼ˆåŒå‘æ¨¡å¼ï¼Œè¡¥å……ç›¸æœºIDï¼‰
        query_modal = args.mode.split("to")[0]
        gall_modal = args.mode.split("to")[1]
        query_img, query_label = process_test_regdb(data_path, trial=args.trial, modality=query_modal)
        gall_img, gall_label = process_test_regdb(data_path, trial=args.trial, modality=gall_modal)
        query_cam = np.ones_like(query_label) if query_modal == "visible" else np.ones_like(query_label)*2
        gall_cam = np.ones_like(gall_label)*2 if gall_modal == "thermal" else np.ones_like(gall_label)

    # æµ‹è¯•é›†åŠ è½½ï¼ˆç»Ÿä¸€æ ¼å¼ï¼Œé€‚é…è®ºæ–‡è¯„ä¼°ï¼‰
    gallset = TestData(gall_img, gall_label, transform_test=transform_test, img_size=(args.img_w, args.img_h))
    queryset = TestData(query_img, query_label, transform_test=transform_test, img_size=(args.img_w, args.img_h))
    test_loader = {
        "query_loader": data.DataLoader(
            queryset, batch_size=args.test_batch_size, shuffle=False, num_workers=args.workers
        ),
        "gall_loader": data.DataLoader(
            gallset, batch_size=args.test_batch_size, shuffle=False, num_workers=args.workers
        )
    }
    test_info = {
        "query_pids": query_label, "gall_pids": gall_label,
        "query_cams": query_cam, "gall_cams": gall_cam
    }

    # æ•°æ®é›†ç»Ÿè®¡ï¼ˆè®ºæ–‡å®éªŒè®°å½•è¦æ±‚ï¼‰
    n_class_vis = len(np.unique(trainset_step2.train_color_label))
    n_class_ir = len(np.unique(trainset_step2.train_thermal_label))
    print(f"æ•°æ®é›†ç»Ÿè®¡ï¼ˆ{args.dataset}ï¼‰ï¼š")
    print("  ----------------------------")
    print("  subset   | # ids | # images")
    print("  ----------------------------")
    print(f"  visible  | {n_class_vis:5d} | {len(trainset_step2.train_color_label):8d}")
    print(f"  thermal  | {n_class_ir:5d} | {len(trainset_step2.train_thermal_label):8d}")
    print("  ----------------------------")
    print(f"  query    | {len(np.unique(query_label)):5d} | {len(query_label):8d}")
    print(f"  gallery  | {len(np.unique(gall_label)):5d} | {len(gall_label):8d}")
    print("  ----------------------------")
    print(f"æ•°æ®åŠ è½½è€—æ—¶ï¼š{time.time() - t_start:.3f}s\n")

    ## 3. æ¨¡å‹åˆå§‹åŒ–ï¼ˆæ›¿æ¢ä¸ºCSANetï¼ŒåŸºäºTransReIDéª¨å¹²ï¼‰
    print("==> åˆå§‹åŒ–CSANetæ¨¡å‹...")
    main_net = CSANet(
        class_num=n_class_vis,
        es1=CSANET_CONFIG["train_stage"]["step_i_epoch"],
        es2=CSANET_CONFIG["train_stage"]["step_ii_epoch"]
    ).to(device)

    # åŠ è½½é¢„è®­ç»ƒ/Resumeï¼ˆå…¼å®¹åŸæœ‰é€»è¾‘ï¼‰
    start_epoch = args.start_epoch
    best_rank1 = 0.0
    best_mAP = 0.0
    best_mINP = 0.0
    if args_main.resume and os.path.exists(args_main.resume_path):
        checkpoint = torch.load(args_main.resume_path, map_location=device)
        main_net.load_state_dict(checkpoint["main_net"])
        start_epoch = checkpoint.get("epoch", args.start_epoch)
        best_rank1 = checkpoint.get("best_rank1", 0.0)
        print(f"åŠ è½½Resumeæ¨¡å‹ï¼š{args_main.resume_path}ï¼Œèµ·å§‹epochï¼š{start_epoch}\n")
    else:
        print("æœªåŠ è½½Resumeæ¨¡å‹ï¼Œä»å¤´å¼€å§‹è®­ç»ƒ\n")

    ## 4. Step-Iï¼šå•æ¨¡æ€å¯¹æ¯”èšç±»ï¼ˆè®ºæ–‡Algorithm 1 Step1-7ï¼‰
    print("="*60)
    print(f"Step-Iï¼šå•æ¨¡æ€å¯¹æ¯”èšç±»ï¼ˆEpoch {start_epoch} ~ {CSANET_CONFIG['train_stage']['step_i_epoch']}ï¼‰")
    print("="*60)

    # å†»ç»“Step-Iä¸è®­ç»ƒçš„æ¨¡å—ï¼ˆTBGM/CAP/IPCCï¼‰
    freeze_modules(
        main_net,
        freeze_backbone=False,  # Step-Iè®­ç»ƒéª¨å¹²ç½‘ç»œ
        freeze_tbgm_cap_ipcc=True
    )

    # åˆå§‹åŒ–Step-IæŸå¤±ï¼ˆä»…ClusterNCEï¼Œè®ºæ–‡Eq.5ï¼‰
    step1_loss_fn = CSANetTotalLoss(
        lambda_nce=1.0, lambda_cc=0.0, lambda_ipcc=0.0  # Step-Iæ— è·¨æ¨¡æ€æŸå¤±
    )

    # åˆå§‹åŒ–Step-Iä¼˜åŒ–å™¨ï¼ˆä»…ä¼˜åŒ–éª¨å¹²ï¼Œå­¦ä¹ ç‡æŒ‰è®ºæ–‡è®¾å®šï¼‰
    optimizer_step1 = select_optimizer(
        args, main_net,
        base_lr=args.base_lr if hasattr(args, "base_lr") else 3e-4,
        module_lr_ratio=1.0  # Step-Iæ— æ¨¡å—ï¼Œæ¯”ä¾‹ä¸º1.0
    )

    # Step-Iæ ¸å¿ƒå˜é‡
    vis_memory = None  # å¯è§å…‰è®°å¿†åº“ï¼ˆMvï¼Œè®ºæ–‡Eq.3ï¼‰
    ir_memory = None   # çº¢å¤–è®°å¿†åº“ï¼ˆMrï¼‰
    train_thermal_pseudo_label = np.random.randint(0, n_class_vis, len(trainset_step2.train_thermal_label))

    for epoch in range(start_epoch, CSANET_CONFIG["train_stage"]["step_i_epoch"] + 1):
        # è°ƒæ•´å­¦ä¹ ç‡ï¼ˆStep-Iå‡æ¸©ç­–ç•¥ï¼Œé¿å…åˆå§‹æ¢¯åº¦çˆ†ç‚¸ï¼‰
        adjust_learning_rate(optimizer_step1, current_epoch=epoch, stage="step_i")

        # 1. å•æ¨¡æ€é‡‡æ ·å™¨ï¼ˆä»…é‡‡æ ·å¯è§å…‰ï¼Œçº¢å¤–ä¾èµ–ä¼ªæ ‡ç­¾ï¼‰
        vis_sampler = CSANetSingleModalitySampler(
            modal_pseudo_label=trainset_step2.train_color_label,
            num_pos=args.num_pos,
            batch_size=args.train_batch_size
        )
        trainset_step2.cIndex = vis_sampler.index1
        trainloader_vis = data.DataLoader(
            trainset_step2, batch_size=args.train_batch_size * args.num_pos,
            sampler=vis_sampler, num_workers=args.workers, drop_last=True
        )

        # 2. å¯è§å…‰å•æ¨¡æ€è®­ç»ƒï¼ˆè®ºæ–‡Eq.5ä¼˜åŒ–ï¼‰
        train_stats = trainer(
            args=args,
            epoch=epoch,
            main_net=main_net,
            optimizer=optimizer_step1,
            trainloader=trainloader_vis,
            total_loss_fn=step1_loss_fn,
            logger=sys.stdout,
            writer=writer,
            stage="step_i",
            modal="vis"
        )

        # 3. OTLA-SKä¼˜åŒ–çº¢å¤–ä¼ªæ ‡ç­¾ï¼ˆæ¯5 epochä¸€æ¬¡ï¼Œæå‡ä¼ªæ ‡ç­¾å¯é æ€§ï¼‰
        if epoch % 5 == 0:
            ir_sampler = CSANetSingleModalitySampler(
                modal_pseudo_label=train_thermal_pseudo_label,
                num_pos=args.num_pos,
                batch_size=args.train_batch_size
            )
            trainset_step2.tIndex = ir_sampler.index2
            trainloader_ir = data.DataLoader(
                trainset_step2, batch_size=args.train_batch_size * args.num_pos,
                sampler=ir_sampler, num_workers=args.workers, drop_last=True
            )

            # è°ƒç”¨OTLA-SKä¼˜åŒ–ä¼ªæ ‡ç­¾
            ir_pseudo_op, ir_pseudo_mp, ir_real_label, unique_tIdx, conf, sk_stats = cpu_sk_ir_trainloader(
                args=args,
                main_net=main_net,
                trainloader=trainloader_ir,
                tIndex=ir_sampler.index2,
                n_class=n_class_ir,
                curriculum_mask=None  # Step-Iæ— è¯¾ç¨‹åˆ’åˆ†
            )
            # æ›´æ–°çº¢å¤–ä¼ªæ ‡ç­¾
            train_thermal_pseudo_label[unique_tIdx] = ir_pseudo_op.numpy()
            # è¯„ä¼°ä¼ªæ ‡ç­¾è´¨é‡ï¼ˆARIï¼Œè®ºæ–‡è¡¨VIIIèšç±»è´¨é‡æŒ‡æ ‡ï¼‰
            ari_stats = evaluate_pseudo_label(
                pseudo_label=train_thermal_pseudo_label[unique_tIdx],
                true_label=ir_real_label.numpy(),
                confidence=conf,
                dataset=args.dataset,
                course="step_i_ir"
            )
            print(f"Step-I Epoch {epoch}ï¼šçº¢å¤–ä¼ªæ ‡ç­¾ARI={ari_stats['ARI']:.4f}ï¼Œé«˜ç½®ä¿¡åº¦å æ¯”={sk_stats['high_confidence_ratio']:.2%}\n")

        # 4. å®šæœŸæ›´æ–°è®°å¿†åº“ï¼ˆè®ºæ–‡Eq.3ï¼Œæ¯5 epochï¼‰
        if epoch % CSANET_CONFIG["memory"]["update_freq"] == 0:
            print(f"Step-I Epoch {epoch}ï¼šæ›´æ–°å•æ¨¡æ€è®°å¿†åº“...")
            # æå–å•æ¨¡æ€ç‰¹å¾
            vis_feats = main_net.extract_modal_feats(train_loaders["step_i_vis"], device=device, modal="vis")
            ir_feats = main_net.extract_modal_feats(train_loaders["step_i_ir"], device=device, modal="ir")
            # æ„å»º/æ›´æ–°è®°å¿†åº“ï¼ˆåŠ¨é‡æ›´æ–°ï¼‰
            vis_memory, vis_pid2idx = build_modal_memory(
                modal_feats=vis_feats,
                modal_pseudo_label=trainset_step1_vis.train_color_label,
                old_memory=vis_memory,
                momentum=CSANET_CONFIG["memory"]["momentum"]
            )
            ir_memory, ir_pid2idx = build_modal_memory(
                modal_feats=ir_feats,
                modal_pseudo_label=trainset_step1_ir.train_thermal_label,
                old_memory=ir_memory,
                momentum=CSANET_CONFIG["memory"]["momentum"]
            )
            # è®°å¿†åº“ä¼ å…¥æ¨¡å‹
            main_net.init_memory(len(vis_pid2idx), len(ir_pid2idx), device=device)
            main_net.update_memory(vis_feats, trainset_step1_vis.train_color_label, ir_feats, trainset_step1_ir.train_thermal_label)
            # ä¿å­˜è®°å¿†åº“
            torch.save({"vis_memory": vis_memory, "ir_memory": ir_memory}, os.path.join(memory_path, f"memory_epoch{epoch}.pth"))

        # 5. Step-Iæµ‹è¯•ï¼ˆæ¯10 epochï¼ŒéªŒè¯èšç±»æ•ˆæœï¼‰
        if epoch % 10 == 0:
            print(f"Step-I Epoch {epoch}ï¼šæµ‹è¯•å•æ¨¡æ€èšç±»æ•ˆæœ...")
            cmc, mAP, mINP, test_stats = tester(
                args=args,
                epoch=epoch,
                main_net=main_net,
                test_loader=test_loader,
                test_info=test_info,
                dataset=args.dataset,
                test_mode=args.mode,
                logger=test_log,
                writer=writer
            )
            print(f"Step-I Epoch {epoch} æµ‹è¯•ç»“æœï¼šRank-1={test_stats['Rank-1']:.2f}%ï¼ŒmAP={test_stats['mAP']:.2f}%\n")

    # Step-Iç»“æŸï¼šä¿å­˜ä¸­é—´æ¨¡å‹
    step1_ckpt = {
        "main_net": main_net.state_dict(),
        "vis_memory": vis_memory,
        "ir_memory": ir_memory,
        "epoch": CSANET_CONFIG["train_stage"]["step_i_epoch"],
        "best_rank1": best_rank1
    }
    torch.save(step1_ckpt, os.path.join(model_path, "step1_final.pth"))
    print(f"Step-Iè®­ç»ƒç»“æŸï¼Œæ¨¡å‹ä¿å­˜è‡³ï¼š{os.path.join(model_path, 'step1_final.pth')}\n")

    ## 5. Step-IIï¼šè·¨æ¨¡æ€è‡ªæ­¥å…³è”ï¼ˆè®ºæ–‡Algorithm 1 Step8-22ï¼‰
    print("="*60)
    print(f"Step-IIï¼šè·¨æ¨¡æ€è‡ªæ­¥å…³è”ï¼ˆEpoch {CSANET_CONFIG['train_stage']['step_i_epoch']+1} ~ {CSANET_CONFIG['train_stage']['total_epoch']}ï¼‰")
    print("="*60)

    # è§£å†»TBGM/CAP/IPCCæ¨¡å—ï¼ˆStep-IIè®­ç»ƒå…¨æ¨¡å—ï¼‰
    freeze_modules(
        main_net,
        freeze_backbone=True,  # å†»ç»“éª¨å¹²ï¼Œä»…å¾®è°ƒæ¨¡å—ï¼ˆè®ºæ–‡æ¨èï¼‰
        freeze_tbgm_cap_ipcc=False
    )

    # åˆå§‹åŒ–Step-IIæŸå¤±ï¼ˆNCE + CC + IPCCï¼Œè®ºæ–‡Eq.21ï¼‰
    step2_loss_fn = CSANetTotalLoss(
        lambda_nce=1.0,
        lambda_cc=1.0,
        lambda_ipcc=0.5  # è®ºæ–‡Eq.21æƒé‡è®¾å®š
    )

    # åˆå§‹åŒ–Step-IIä¼˜åŒ–å™¨ï¼ˆæ¨¡å—å­¦ä¹ ç‡ä¸ºéª¨å¹²10å€ï¼Œè®ºæ–‡ğŸ”¶1-209ï¼‰
    optimizer_step2 = select_optimizer(
        args, main_net,
        base_lr=(args.base_lr if hasattr(args, "base_lr") else 3e-4) * 0.1,  # éª¨å¹²lré™ä¸ºStep-Içš„1/10
        module_lr_ratio=10
    )

    # Step-IIæ ¸å¿ƒå˜é‡
    start_epoch_step2 = CSANET_CONFIG["train_stage"]["step_i_epoch"] + 1
    # TBGMè¯¾ç¨‹åˆ’åˆ†ï¼ˆè®ºæ–‡Step12ï¼Œç”Ÿæˆæ ·æœ¬çº§è¯¾ç¨‹æ©ç ï¼‰
    print("Step-IIï¼šTBGMæ¨¡å—åˆ’åˆ†ç®€å•/ä¸­ç­‰/å¤æ‚è¯¾ç¨‹...")
    vis_feats_step2 = main_net.extract_modal_feats(train_loaders["step_i_vis"], device=device, modal="vis")
    ir_feats_step2 = main_net.extract_modal_feats(train_loaders["step_i_ir"], device=device, modal="ir")
    # TBGMè¾“å‡ºPIDâ†’è¯¾ç¨‹ç­‰çº§æ˜ å°„ï¼ˆ0=plainï¼Œ1=moderateï¼Œ2=intricateï¼‰
    vis_tbgm_course = main_net.tbgm(vis_feats_step2, vis_memory, vis_pid2idx)
    ir_tbgm_course = main_net.tbgm(ir_feats_step2, ir_memory, ir_pid2idx)
    # ç”Ÿæˆæ ·æœ¬çº§è¯¾ç¨‹æ©ç 
    vis_curriculum_mask = generate_curriculum_mask(
        modal_pseudo_label=trainset_step2.train_color_label,
        tbgm_curriculum=vis_tbgm_course
    )
    ir_curriculum_mask = generate_curriculum_mask(
        modal_pseudo_label=trainset_step2.train_thermal_label,
        tbgm_curriculum=ir_tbgm_course
    )

    for epoch in range(start_epoch_step2, CSANET_CONFIG["train_stage"]["total_epoch"] + 1):
        # ç¡®å®šå½“å‰è¯¾ç¨‹é˜¶æ®µï¼ˆè®ºæ–‡Step15-17ï¼‰
        current_course = get_current_curriculum(
            epoch=epoch - start_epoch_step2 + 1,
            step_ii_total=CSANET_CONFIG["train_stage"]["step_ii_epoch"]
        )
        print(f"\nStep-II Epoch {epoch}ï¼šå½“å‰è¯¾ç¨‹é˜¶æ®µ={current_course}")

        # 1. CAPæ¨¡å—ç”Ÿæˆè·¨æ¨¡æ€å…³è”å­—å…¸ï¼ˆè®ºæ–‡Step13-14ï¼ŒDv2r/Dr2vï¼‰
        cap_mapping = main_net.cap(
            src_complex_feats=vis_feats_step2,
            src_plain_memory=vis_memory,
            tgt_plain_memory=ir_memory,
            src_pid2idx=vis_pid2idx,
            tgt_pid2idx=ir_pid2idx
        )
        print(f"CAPæ¨¡å—ç”Ÿæˆå…³è”å¯¹æ•°ï¼švis2ir={len(cap_mapping.get('vis2ir', {}))}ï¼Œir2vis={len(cap_mapping.get('ir2vis', {}))}")

        # 2. è¯¾ç¨‹é‡‡æ ·å™¨ï¼ˆä»…é‡‡æ ·å½“å‰è¯¾ç¨‹æ ·æœ¬ï¼Œè®ºæ–‡Step15-17ï¼‰
        sampler_step2 = CSANetCurriculumSampler(
            train_color_pseudo_label=trainset_step2.train_color_label,
            train_thermal_pseudo_label=train_thermal_pseudo_label,
            color_curriculum_mask=vis_curriculum_mask,
            thermal_curriculum_mask=ir_curriculum_mask,
            cap_mapping=cap_mapping.get("vis2ir", {}),
            num_pos=args.num_pos,
            batch_size=args.train_batch_size,
            current_stage=current_course
        )
        trainset_step2.cIndex = sampler_step2.index1
        trainset_step2.tIndex = sampler_step2.index2
        trainloader_step2 = data.DataLoader(
            trainset_step2, batch_size=args.train_batch_size * args.num_pos,
            sampler=sampler_step2, num_workers=args.workers, drop_last=True
        )

        # 3. OTLA-SKä¼˜åŒ–çº¢å¤–ä¼ªæ ‡ç­¾ï¼ˆä»…ä¸­ç­‰/å¤æ‚è¯¾ç¨‹ï¼Œè®ºæ–‡Step14åä¼˜åŒ–ï¼‰
        if current_course in CSANET_CONFIG["curriculum"]["optimize_courses"]:
            print(f"Step-II Epoch {epoch}ï¼šOTLA-SKä¼˜åŒ–çº¢å¤–ä¼ªæ ‡ç­¾...")
            ir_pseudo_op, ir_pseudo_mp, ir_real_label, unique_tIdx, conf, sk_stats = cpu_sk_ir_trainloader(
                args=args,
                main_net=main_net,
                trainloader=trainloader_step2,
                tIndex=sampler_step2.index2,
                n_class=n_class_ir,
                curriculum_mask=ir_curriculum_mask
            )
            train_thermal_pseudo_label[unique_tIdx] = ir_pseudo_op.numpy()
            print(f"OTLA-SKä¼˜åŒ–ç»“æœï¼šé«˜ç½®ä¿¡åº¦æ ·æœ¬å æ¯”={sk_stats['high_confidence_ratio']:.2%}")

        # 4. Step-IIè®­ç»ƒï¼ˆå«NCE+CC+IPCCæŸå¤±ï¼Œè®ºæ–‡Eq.21ï¼‰
        train_stats = trainer(
            args=args,
            epoch=epoch,
            main_net=main_net,
            optimizer=optimizer_step2,
            trainloader=trainloader_step2,
            total_loss_fn=step2_loss_fn,
            logger=sys.stdout,
            writer=writer,
            curriculum_mask_vis=vis_curriculum_mask,
            curriculum_mask_ir=ir_curriculum_mask,
            cap_mapping=cap_mapping,
            ref_memory=vis_memory,  # IPCCå‚è€ƒè®°å¿†åº“ï¼ˆç®€å•è¯¾ç¨‹ï¼Œè®ºæ–‡Step17ï¼‰
            stage="step_ii"
        )

        # 5. Step-IIæµ‹è¯•ï¼ˆæ¯5 epochï¼Œè®ºæ–‡å®éªŒè®°å½•ï¼‰
        if epoch % args.eval_epoch == 0:
            print(f"Step-II Epoch {epoch}ï¼šæµ‹è¯•è·¨æ¨¡æ€åŒ¹é…æ•ˆæœ...")
            cmc, mAP, mINP, test_stats = tester(
                args=args,
                epoch=epoch,
                main_net=main_net,
                test_loader=test_loader,
                test_info=test_info,
                dataset=args.dataset,
                test_mode=args.mode,
                logger=test_log,
                writer=writer
            )

            # ä¿å­˜æœ€ä½³æ¨¡å‹
            if test_stats["Rank-1"] > best_rank1:
                best_rank1 = test_stats["Rank-1"]
                best_epoch = epoch
                best_mAP = test_stats["mAP"]
                best_mINP = test_stats["mINP"]
                best_ckpt = {
                    "main_net": main_net.state_dict(),
                    "cmc": cmc,
                    "mAP": mAP,
                    "mINP": mINP,
                    "epoch": epoch,
                    "best_rank1": best_rank1
                }
                torch.save(best_ckpt, os.path.join(model_path, "best_checkpoint.pth"))
                print(f"æ›´æ–°æœ€ä½³æ¨¡å‹ï¼šEpoch {epoch}ï¼ŒRank-1={best_rank1:.2f}%")

            # ä¿å­˜å®šæœŸæ¨¡å‹
            if epoch % args.save_epoch == 0:
                regular_ckpt = {
                    "main_net": main_net.state_dict(),
                    "cmc": cmc,
                    "mAP": mAP,
                    "mINP": mINP,
                    "epoch": epoch
                }
                torch.save(regular_ckpt, os.path.join(model_path, f"checkpoint_epoch{epoch}.pth"))

            # æ‰“å°ä¸è®°å½•ç»“æœ
            print(f"å½“å‰æµ‹è¯•ç»“æœï¼šRank-1={test_stats['Rank-1']:.2f}% | mAP={test_stats['mAP']:.2f}% | mINP={test_stats['mINP']:.2f}%")
            print(f"æœ€ä½³ç»“æœï¼šEpoch {best_epoch} | Rank-1={best_rank1:.2f}% | mAP={best_mAP:.2f}% | mINP={best_mINP:.2f}%", file=test_log)
            test_log.flush()

        # 6. å®šæœŸæ›´æ–°è®°å¿†åº“ï¼ˆStep-IIæ¯10 epochï¼Œè®ºæ–‡Step21ï¼‰
        if epoch % (CSANET_CONFIG["memory"]["update_freq"] * 2) == 0:
            print(f"Step-II Epoch {epoch}ï¼šæ›´æ–°è·¨æ¨¡æ€è®°å¿†åº“...")
            vis_feats_new = main_net.extract_modal_feats(train_loaders["step_i_vis"], device=device, modal="vis")
            ir_feats_new = main_net.extract_modal_feats(train_loaders["step_i_ir"], device=device, modal="ir")
            main_net.update_memory(vis_feats_new, trainset_step1_vis.train_color_label, ir_feats_new, trainset_step1_ir.train_thermal_label)
            torch.save({"vis_memory": main_net.vis_memory, "ir_memory": main_net.ir_memory}, os.path.join(memory_path, f"memory_epoch{epoch}.pth"))

    ## 6. è®­ç»ƒç»“æŸï¼šæ±‡æ€»ç»“æœ
    print("\n" + "="*60)
    print(f"CSANetè®­ç»ƒå®Œæˆï¼æ€»epochï¼š{CSANET_CONFIG['train_stage']['total_epoch']}")
    print(f"æœ€ä½³å®éªŒç»“æœï¼š")
    print(f"  Epoch: {best_epoch}")
    print(f"  Rank-1: {best_rank1:.2f}% | mAP: {best_mAP:.2f}% | mINP: {best_mINP:.2f}%")
    print("="*60)

    # å…³é—­èµ„æº
    test_log.close()
    writer.close()
    torch.cuda.empty_cache()

if __name__ == "__main__":
    # å‘½ä»¤è¡Œå‚æ•°è§£æï¼ˆè¡¥å……CSANetå¿…è¦å‚æ•°ï¼‰
    parser = argparse.ArgumentParser(description="CSANet Training Pipeline")
    parser.add_argument("--config", default="config/csanet.yaml", help="CSANeté…ç½®æ–‡ä»¶è·¯å¾„")
    parser.add_argument("--resume", action="store_true", help="æ˜¯å¦ä»checkpointæ¢å¤è®­ç»ƒ")
    parser.add_argument("--resume_path", default="", help="checkpointè·¯å¾„")
    parser.add_argument("--cudnn_benchmark", action="store_true", default=True, help="å¯ç”¨cudnnåŠ é€Ÿ")
    args_main = parser.parse_args()

    # åŠ è½½yamlé…ç½®å¹¶è¡¥å……é»˜è®¤å‚æ•°
# åŠ è½½yamlé…ç½®å¹¶è¡¥å……é»˜è®¤å‚æ•°ï¼ˆæŒ‡å®šutf-8ç¼–ç ï¼Œè§£å†³ä¸­æ–‡/ç‰¹æ®Šå­—ç¬¦è§£ç é—®é¢˜ï¼‰
    with open(args_main.config, "r", encoding="utf-8") as f:
        args = yaml.load(f, Loader=yaml.FullLoader)
    args = easydict.EasyDict(args)

    # è¡¥å……CSANeté»˜è®¤å‚æ•°ï¼ˆè¦†ç›–yamlæœªå®šä¹‰é¡¹ï¼‰
    if not hasattr(args, "base_lr"):
        args.base_lr = 3e-4  # è®ºæ–‡Transformeréª¨å¹²åŸºç¡€å­¦ä¹ ç‡
    if not hasattr(args, "eval_epoch"):
        args.eval_epoch = 5  # æ¯5 epochæµ‹è¯•ä¸€æ¬¡
    if not hasattr(args, "save_epoch"):
        args.save_epoch = 10  # æ¯10 epochä¿å­˜ä¸€æ¬¡æ¨¡å‹

    # å¯åŠ¨ä¸»è®­ç»ƒæµç¨‹
    main_worker(args, args_main)