import os
import sys
import errno
import random
import copy
import numpy as np
from collections import defaultdict, Counter
import torch
import torch.nn.functional as F
from torch.utils.data.sampler import Sampler
from sklearn.metrics import adjusted_rand_score
from PIL import Image

# -------------------------- CSANetå…¨å±€é…ç½®ï¼ˆä¸¥æ ¼éµå¾ªè®ºæ–‡è®¾å®šï¼‰ --------------------------
CSANET_CONFIG = {
    "curriculum": {
        "step_ii_total": 40,  # Step-IIæ€»epochæ•°ï¼ˆè®ºæ–‡Step-I 20epochï¼ŒStep-II 40epochï¼‰ğŸ”¶1-209
        "plain_ratio": 1/3,    # Step-IIå‰1/3ä¸ºç®€å•è¯¾ç¨‹ï¼ˆğŸ”¶1-210 Algorithm 1ï¼‰
        "moderate_ratio": 2/3  # Step-IIä¸­é—´1/3ä¸ºä¸­ç­‰è¯¾ç¨‹ï¼Œå1/3ä¸ºå¤æ‚è¯¾ç¨‹
    },
    "memory": {
        "momentum": 0.9,       # è®°å¿†åº“åŠ¨é‡æ›´æ–°ç³»æ•°ï¼ˆå€Ÿé‰´ClusterContrastï¼‰ğŸ”¶1-134
        "tau": 0.05            # æ¸©åº¦ç³»æ•°ï¼ˆæ‰€æœ‰å¯¹æ¯”æŸå¤±ã€æ¦‚ç‡å“åº”ç»Ÿä¸€è®¾ä¸º0.05ï¼‰ğŸ”¶1-133ã€ğŸ”¶1-182
    },
    "dbscan": {
        "sysu_eps": 0.6,       # SYSU-MM01çš„DBSCANæœ€å¤§è·ç¦»ğŸ”¶1-209
        "regdb_eps": 0.3,      # RegDBçš„DBSCANæœ€å¤§è·ç¦»ğŸ”¶1-209
        "min_samples": 2       # DBSCANæœ€å°èšç±»æ ·æœ¬æ•°ï¼ˆé¿å…å•ç‚¹èšç±»ï¼‰ğŸ”¶1-131
    },
    "eval": {
        "metrics": ["rank1", "mAP", "mINP"]  # è®ºæ–‡æ ¸å¿ƒè¯„ä¼°æŒ‡æ ‡ğŸ”¶1-206
    }
}

# -------------------------- åŸºç¡€æ•°æ®åŠ è½½ä¸ç´¢å¼•ç”Ÿæˆå·¥å…· --------------------------
def load_data(input_data_path: str) -> tuple[list[str], list[int]]:
    """
    åŠ è½½æ•°æ®é›†åˆ—è¡¨æ–‡ä»¶ï¼ˆæ ¼å¼ï¼š"img_path label"ï¼‰ï¼Œé€‚é…RegDB/SYSU-MM01æµ‹è¯•é›†åŠ è½½ğŸ”¶1-204ã€ğŸ”¶1-205
    Args:
        input_data_path: åˆ—è¡¨æ–‡ä»¶è·¯å¾„
    Returns:
        file_image: å›¾åƒè·¯å¾„åˆ—è¡¨
        file_label: å›¾åƒå¯¹åº”æ ‡ç­¾åˆ—è¡¨
    """
    if not os.path.exists(input_data_path):
        raise FileNotFoundError(f"æ•°æ®åˆ—è¡¨æ–‡ä»¶ä¸å­˜åœ¨ï¼š{input_data_path}")
    
    with open(input_data_path, 'rt') as f:
        data_file_list = f.read().splitlines()
    
    file_image = []
    file_label = []
    for line in data_file_list:
        line = line.strip()
        if not line:
            continue
        parts = line.split(' ')
        if len(parts) != 2:
            print(f"è­¦å‘Šï¼šæ— æ•ˆè¡Œæ ¼å¼ï¼Œè·³è¿‡ï¼š{line}")
            continue
        img_path, label_str = parts
        try:
            label = int(label_str)
        except ValueError:
            print(f"è­¦å‘Šï¼šæ ‡ç­¾æ ¼å¼é”™è¯¯ï¼Œè·³è¿‡ï¼š{line}")
            continue
        file_image.append(img_path)
        file_label.append(label)
    
    return file_image, file_label


def GenIdx(train_color_label: np.ndarray, train_thermal_label: np.ndarray) -> tuple[list[list[int]], list[list[int]]]:
    """
    ç”ŸæˆåŒæ¨¡æ€èº«ä»½-æ ·æœ¬ç´¢å¼•æ˜ å°„ï¼Œé€‚é…æœ‰ç›‘ç£/ä¼ªç›‘ç£åœºæ™¯ä¸‹çš„æ ·æœ¬å®šä½ğŸ”¶1-88
    Args:
        train_color_label: å¯è§å…‰æ¨¡æ€æ ‡ç­¾ï¼ˆçœŸå®/ä¼ªæ ‡ç­¾ï¼‰
        train_thermal_label: çº¢å¤–æ¨¡æ€æ ‡ç­¾ï¼ˆçœŸå®/ä¼ªæ ‡ç­¾ï¼‰
    Returns:
        color_pos: å¯è§å…‰èº«ä»½-ç´¢å¼•åˆ—è¡¨ï¼ˆå¦‚[[0,2], [1,4]]è¡¨ç¤ºID0å¯¹åº”ç´¢å¼•0/2ï¼‰
        thermal_pos: çº¢å¤–èº«ä»½-ç´¢å¼•åˆ—è¡¨
    """
    # ç”Ÿæˆå¯è§å…‰ç´¢å¼•æ˜ å°„
    color_pos = []
    unique_color_labels = np.unique(train_color_label)
    for label in unique_color_labels:
        idx = [k for k, v in enumerate(train_color_label) if v == label]
        color_pos.append(idx)
    
    # ç”Ÿæˆçº¢å¤–ç´¢å¼•æ˜ å°„
    thermal_pos = []
    unique_thermal_labels = np.unique(train_thermal_label)
    for label in unique_thermal_labels:
        idx = [k for k, v in enumerate(train_thermal_label) if v == label]
        thermal_pos.append(idx)
    
    return color_pos, thermal_pos


def GenIdx_single(label: np.ndarray) -> tuple[list[list[int]], np.ndarray]:
    """
    ç”Ÿæˆå•æ¨¡æ€èº«ä»½-æ ·æœ¬ç´¢å¼•æ˜ å°„ä¸èº«ä»½å æ¯”ï¼Œé€‚é…Step-Iå•æ¨¡æ€èšç±»ğŸ”¶1-132
    Args:
        label: å•æ¨¡æ€æ ‡ç­¾ï¼ˆçœŸå®/ä¼ªæ ‡ç­¾ï¼‰
    Returns:
        pos: èº«ä»½-ç´¢å¼•åˆ—è¡¨
        prob: å„èº«ä»½æ ·æœ¬å æ¯”ï¼ˆç”¨äºé‡‡æ ·æƒé‡ï¼‰
    """
    pos = []
    num = []
    max_label = np.max(label) if len(label) > 0 else 0
    unique_labels = np.unique(label)
    
    for i in range(max_label + 1):
        if i in unique_labels:
            idx = [k for k, v in enumerate(label) if v == i]
            pos.append(idx)
            num.append(len(idx))
        else:
            pos.append([])
            num.append(0)
    
    # è®¡ç®—å„èº«ä»½å æ¯”ï¼ˆé¿å…é™¤ä»¥é›¶ï¼‰
    total = np.sum(num)
    prob = np.array(num) / total if total > 0 else np.zeros_like(num)
    return pos, prob


def GenCamIdx(gall_img: list[str], gall_label: np.ndarray, mode: str = "all") -> list[list[int]]:
    """
    ç”ŸæˆSYSU-MM01ç”»å»Šé›†çš„â€œèº«ä»½-ç›¸æœºâ€ç´¢å¼•æ˜ å°„ï¼Œé€‚é…æµ‹è¯•é›†ç›¸æœºè¿‡æ»¤ğŸ”¶1-204
    Args:
        gall_img: ç”»å»Šé›†å›¾åƒè·¯å¾„åˆ—è¡¨
        gall_label: ç”»å»Šé›†æ ‡ç­¾
        mode: æµ‹è¯•æ¨¡å¼ï¼ˆ"all"â†’4ä¸ªå¯è§å…‰ç›¸æœºï¼›"indoor"â†’2ä¸ªå®¤å†…ç›¸æœºï¼‰
    Returns:
        sample_pos: ï¼ˆèº«ä»½-ç›¸æœºï¼‰å¯¹åº”çš„æ ·æœ¬ç´¢å¼•åˆ—è¡¨
    """
    # è®ºæ–‡SYSU-MM01ç›¸æœºè®¾å®šï¼šallæ¨¡å¼ç”¨cam1/2/4/5ï¼Œindooræ¨¡å¼ç”¨cam1/2ğŸ”¶1-204
    cam_idx_map = {"all": [1,2,4,5], "indoor": [1,2]}
    if mode not in cam_idx_map:
        raise ValueError(f"æ— æ•ˆæ¨¡å¼ï¼š{mode}ï¼Œä»…æ”¯æŒ'all'/'indoor'")
    target_cams = cam_idx_map[mode]
    
    # æå–ç”»å»Šé›†å›¾åƒçš„ç›¸æœºIDï¼ˆè·¯å¾„å10ä½ä¸ºç›¸æœºæ ‡è¯†ï¼Œå¦‚"cam1/..."â†’1ï¼‰
    gall_cam = []
    for img_path in gall_img:
        try:
            cam_id = int(img_path[-10])  # é€‚é…è·¯å¾„æ ¼å¼ï¼š".../camX/.../xxx.jpg"
            gall_cam.append(cam_id)
        except (IndexError, ValueError):
            print(f"è­¦å‘Šï¼šç›¸æœºIDè§£æå¤±è´¥ï¼Œè·³è¿‡ï¼š{img_path}")
            gall_cam.append(-1)  # æ ‡è®°ä¸ºæ— æ•ˆç›¸æœº
    
    # ç”Ÿæˆâ€œèº«ä»½-ç›¸æœºâ€ç´¢å¼•æ˜ å°„
    sample_pos = []
    unique_labels = np.unique(gall_label)
    for label in unique_labels:
        for cam in target_cams:
            # ç­›é€‰è¯¥èº«ä»½+è¯¥ç›¸æœºçš„æ ·æœ¬ç´¢å¼•
            idx = [k for k, (v, c) in enumerate(zip(gall_label, gall_cam)) if v == label and c == cam]
            if idx:
                sample_pos.append(idx)
    
    return sample_pos

# -------------------------- CSANetæ ¸å¿ƒé‡‡æ ·å™¨ï¼ˆé€‚é…è¯¾ç¨‹å­¦ä¹ ï¼‰ --------------------------
class CSANetCurriculumSampler(Sampler):
    """
    CSANetæ— ç›‘ç£è¯¾ç¨‹é‡‡æ ·å™¨ï¼šæŒ‰â€œç®€å•â†’ä¸­ç­‰â†’å¤æ‚â€é˜¶æ®µé‡‡æ ·åŒæ¨¡æ€æ ·æœ¬ğŸ”¶1-99ã€ğŸ”¶1-210
    æ”¯æŒStep-IIä¸åŒé˜¶æ®µä»…åŠ è½½å¯¹åº”è¯¾ç¨‹æ ·æœ¬ï¼Œä¸”åŒæ¨¡æ€æ ·æœ¬æŒ‰CAPå…³è”åŒ¹é…ğŸ”¶1-166
    """
    def __init__(
        self,
        train_color_pseudo_label: np.ndarray,  # å¯è§å…‰ä¼ªæ ‡ç­¾ï¼ˆDBSCANç”Ÿæˆï¼‰
        train_thermal_pseudo_label: np.ndarray, # çº¢å¤–ä¼ªæ ‡ç­¾
        color_curriculum_mask: np.ndarray,     # å¯è§å…‰è¯¾ç¨‹æ©ç ï¼ˆ0=plain,1=moderate,2=intricateï¼‰
        thermal_curriculum_mask: np.ndarray,   # çº¢å¤–è¯¾ç¨‹æ©ç 
        cap_mapping: dict,                     # CAPä¼ é€’çš„è·¨æ¨¡æ€å…³è”ï¼ˆvis_pidâ†’ir_pidï¼‰ğŸ”¶1-174
        num_pos: int = 4,                      # æ¯ä¸ªèº«ä»½é‡‡æ ·æ ·æœ¬æ•°
        batch_size: int = 8,                   # æ¯ä¸ªbatchçš„èº«ä»½æ•°ï¼ˆè®ºæ–‡è®¾å®šï¼‰ğŸ”¶1-208
        current_stage: str = "plain",          # å½“å‰è¯¾ç¨‹é˜¶æ®µ
        dataset_name: str = "sysu"
    ):
        # 1. ç­›é€‰å½“å‰è¯¾ç¨‹çš„æ ·æœ¬å…¨å±€ç´¢å¼•
        stage2level = {"plain": 0, "moderate": 1, "intricate": 2}
        if current_stage not in stage2level:
            raise ValueError(f"æ— æ•ˆé˜¶æ®µï¼š{current_stage}ï¼Œä»…æ”¯æŒ'plain'/'moderate'/'intricate'")
        target_level = stage2level[current_stage]
        
        # ç­›é€‰å¯è§å…‰/çº¢å¤–å½“å‰è¯¾ç¨‹çš„å…¨å±€ç´¢å¼•
        self.color_global_idx = np.where(color_curriculum_mask == target_level)[0]
        self.thermal_global_idx = np.where(thermal_curriculum_mask == target_level)[0]
        
        if len(self.color_global_idx) == 0 or len(self.thermal_global_idx) == 0:
            raise RuntimeError(f"å½“å‰é˜¶æ®µ{current_stage}æ— æœ‰æ•ˆæ ·æœ¬ï¼Œæ£€æŸ¥è¯¾ç¨‹æ©ç ")
        
        # 2. æ„å»ºå½“å‰è¯¾ç¨‹çš„â€œèº«ä»½-å±€éƒ¨ç´¢å¼•â€æ˜ å°„ï¼ˆå±€éƒ¨ç´¢å¼•å¯¹åº”ç­›é€‰åçš„æ ·æœ¬ï¼‰
        # å¯è§å…‰æ˜ å°„
        color_pid_in_stage = train_color_pseudo_label[self.color_global_idx]
        self.color_pid2local = defaultdict(list)
        for local_idx, global_idx in enumerate(self.color_global_idx):
            pid = train_color_pseudo_label[global_idx]
            self.color_pid2local[pid].append(local_idx)
        
        # çº¢å¤–æ˜ å°„
        thermal_pid_in_stage = train_thermal_pseudo_label[self.thermal_global_idx]
        self.thermal_pid2local = defaultdict(list)
        for local_idx, global_idx in enumerate(self.thermal_global_idx):
            pid = train_thermal_pseudo_label[global_idx]
            self.thermal_pid2local[pid].append(local_idx)
        
        # 3. ç­›é€‰æœ‰CAPè·¨æ¨¡æ€å…³è”çš„æœ‰æ•ˆèº«ä»½
        self.valid_vis_pids = [pid for pid in self.color_pid2local.keys() if pid in cap_mapping]
        if len(self.valid_vis_pids) == 0:
            raise RuntimeError(f"å½“å‰é˜¶æ®µ{current_stage}æ— CAPå…³è”èº«ä»½ï¼Œæ£€æŸ¥å…³è”å­—å…¸")
        
        # 4. é‡‡æ ·å‚æ•°åˆå§‹åŒ–
        self.num_pos = num_pos
        self.batch_size = batch_size
        self.cap_mapping = cap_mapping  # vis_pid â†’ ir_pid
        # é‡‡æ ·æ€»é•¿åº¦ï¼šè¦†ç›–2è½®æ‰€æœ‰æ ·æœ¬ï¼ˆé¿å…è®­ç»ƒä¸­æ–­ï¼‰
        self.total_samples = max(len(self.color_global_idx), len(self.thermal_global_idx)) * 2
        self.N = self.total_samples // self.num_pos  # è¿­ä»£æ¬¡æ•°ï¼ˆæ¯ä¸ªæ ·æœ¬å¯¹ç®—1æ¬¡ï¼‰

    def __iter__(self):
        batch_num = self.total_samples // (self.batch_size * self.num_pos)
        for _ in range(batch_num):
            # éšæœºé€‰æ‹©å½“å‰batchçš„å¯è§å…‰èº«ä»½
            batch_vis_pids = np.random.choice(self.valid_vis_pids, self.batch_size, replace=False)
            for vis_pid in batch_vis_pids:
                # 1. é‡‡æ ·å¯è§å…‰æ ·æœ¬ï¼ˆå½“å‰è¯¾ç¨‹å†…ï¼‰
                vis_local_idx = np.random.choice(
                    self.color_pid2local[vis_pid], 
                    self.num_pos, 
                    replace=len(self.color_pid2local[vis_pid]) < self.num_pos
                )
                vis_global_idx = self.color_global_idx[vis_local_idx]  # è½¬ä¸ºå…¨å±€ç´¢å¼•
                
                # 2. é‡‡æ ·å¯¹åº”çº¢å¤–æ ·æœ¬ï¼ˆæŒ‰CAPå…³è”æ‰¾çº¢å¤–èº«ä»½ï¼‰
                ir_pid = self.cap_mapping[vis_pid]
                if ir_pid not in self.thermal_pid2local:
                    print(f"è­¦å‘Šï¼šçº¢å¤–æ— èº«ä»½{ir_pid}ï¼Œéšæœºé‡‡æ ·çº¢å¤–æ ·æœ¬")
                    ir_local_idx = np.random.choice(
                        range(len(self.thermal_global_idx)), 
                        self.num_pos, 
                        replace=False
                    )
                else:
                    ir_local_idx = np.random.choice(
                        self.thermal_pid2local[ir_pid], 
                        self.num_pos, 
                        replace=len(self.thermal_pid2local[ir_pid]) < self.num_pos
                    )
                ir_global_idx = self.thermal_global_idx[ir_local_idx]  # è½¬ä¸ºå…¨å±€ç´¢å¼•
                
                # 3. è¿”å›ï¼ˆå¯è§å…‰å…¨å±€ç´¢å¼•ï¼Œçº¢å¤–å…¨å±€ç´¢å¼•ï¼‰å¯¹
                for c_idx, t_idx in zip(vis_global_idx, ir_global_idx):
                    yield (c_idx, t_idx)

    def __len__(self):
        return self.N


class CSANetSingleModalitySampler(Sampler):
    """
    CSANetå•æ¨¡æ€é‡‡æ ·å™¨ï¼šç”¨äºStep-Iå•æ¨¡æ€å¯¹æ¯”èšç±»ï¼ˆä»…é‡‡æ ·å•ä¸ªæ¨¡æ€æ ·æœ¬ï¼‰ğŸ”¶1-132
    """
    def __init__(
        self,
        modal_pseudo_label: np.ndarray,  # å•æ¨¡æ€ä¼ªæ ‡ç­¾
        num_pos: int = 4,
        batch_size: int = 8,
        dataset_len: int = None
    ):
        # æ„å»ºâ€œèº«ä»½-æ ·æœ¬ç´¢å¼•â€æ˜ å°„
        self.pid2idx = defaultdict(list)
        for idx, pid in enumerate(modal_pseudo_label):
            self.pid2idx[pid].append(idx)
        
        # ç­›é€‰æœ‰æ•ˆèº«ä»½ï¼ˆæ ·æœ¬æ•°â‰¥num_posï¼‰
        self.valid_pids = [pid for pid in self.pid2idx.keys() if len(self.pid2idx[pid]) >= num_pos]
        if len(self.valid_pids) == 0:
            raise RuntimeError("æ— è¶³å¤Ÿæ ·æœ¬çš„èº«ä»½ï¼Œæ£€æŸ¥DBSCANèšç±»ç»“æœ")
        
        # é‡‡æ ·å‚æ•°åˆå§‹åŒ–
        self.num_pos = num_pos
        self.batch_size = batch_size
        self.dataset_len = dataset_len if dataset_len is not None else len(modal_pseudo_label)
        self.total_samples = self.dataset_len * 2  # è¦†ç›–2è½®é‡‡æ ·
        self.N = self.total_samples // self.num_pos  # è¿­ä»£æ¬¡æ•°

    def __iter__(self):
        batch_num = self.total_samples // (self.batch_size * self.num_pos)
        for _ in range(batch_num):
            # éšæœºé€‰æ‹©å½“å‰batchçš„èº«ä»½
            batch_pids = np.random.choice(self.valid_pids, self.batch_size, replace=False)
            for pid in batch_pids:
                # é‡‡æ ·è¯¥èº«ä»½çš„num_posä¸ªæ ·æœ¬
                sample_idx = np.random.choice(self.pid2idx[pid], self.num_pos, replace=False)
                for idx in sample_idx:
                    yield idx

    def __len__(self):
        return self.N


class IdentitySampler(Sampler):
    """
    æœ‰ç›‘ç£åŒæ¨¡æ€é‡‡æ ·å™¨ï¼ˆåŸºçº¿æ–¹æ³•ç”¨ï¼‰ï¼šåŸºäºçœŸå®æ ‡ç­¾é‡‡æ ·ï¼Œé€‚é…å¯¹æ¯”å®éªŒğŸ”¶1-212
    """
    def __init__(
        self,
        train_color_label: np.ndarray,
        train_thermal_label: np.ndarray,
        color_pos: list[list[int]],
        thermal_pos: list[list[int]],
        num_pos: int = 4,
        batchSize: int = 8,
        dataset_num_size: int = 2
    ):
        self.uni_label = np.unique(train_color_label)
        self.n_classes = len(self.uni_label)
        self.num_pos = num_pos
        self.batchSize = batchSize
        
        # è®¡ç®—é‡‡æ ·æ€»é•¿åº¦
        max_len = np.maximum(len(train_color_label), len(train_thermal_label))
        self.N = dataset_num_size * max_len

        # é¢„ç”Ÿæˆé‡‡æ ·ç´¢å¼•
        self.index1 = []  # å¯è§å…‰ç´¢å¼•
        self.index2 = []  # çº¢å¤–ç´¢å¼•
        batch_num = int(self.N / (batchSize * num_pos)) + 1
        for _ in range(batch_num):
            # éšæœºé€‰æ‹©batchèº«ä»½
            batch_idx = np.random.choice(self.uni_label, batchSize, replace=False)
            for pid in batch_idx:
                # é‡‡æ ·å¯è§å…‰æ ·æœ¬
                color_sample = np.random.choice(color_pos[pid], num_pos)
                # é‡‡æ ·çº¢å¤–æ ·æœ¬
                thermal_sample = np.random.choice(thermal_pos[pid], num_pos)
                # æ‹¼æ¥ç´¢å¼•
                self.index1.extend(color_sample)
                self.index2.extend(thermal_sample)
        
        # æˆªæ–­åˆ°æŒ‡å®šé•¿åº¦
        self.index1 = self.index1[:self.N]
        self.index2 = self.index2[:self.N]

    def __iter__(self):
        return iter(zip(self.index1, self.index2))

    def __len__(self):
        return self.N


class SemiIdentitySampler_pseudoIR(Sampler):
    """
    åŠç›‘ç£ä¼ªæ ‡ç­¾é‡‡æ ·å™¨ï¼ˆåŸºçº¿æ–¹æ³•ç”¨ï¼‰ï¼šé€‚é…çº¢å¤–ä¼ªæ ‡ç­¾åœºæ™¯ï¼Œç”¨äºå¯¹æ¯”å®éªŒğŸ”¶1-212
    """
    def __init__(
        self,
        train_color_label: np.ndarray,
        train_thermal_label: np.ndarray,
        color_pos: list[list[int]],
        num_pos: int = 4,
        batchSize: int = 8,
        dataset_num_size: int = 2
    ):
        self.uni_label_thermal = np.unique(train_thermal_label)
        self.n_classes_thermal = len(self.uni_label_thermal)
        self.num_pos = num_pos
        self.batchSize = batchSize
        
        # ç”Ÿæˆçº¢å¤–èº«ä»½-ç´¢å¼•æ˜ å°„
        self.thermal_pos, _ = GenIdx_single(train_thermal_label)
        
        # è®¡ç®—é‡‡æ ·æ€»é•¿åº¦
        max_len = np.maximum(len(train_color_label), len(train_thermal_label))
        self.N = dataset_num_size * max_len

        # é¢„ç”Ÿæˆbatchèº«ä»½åˆ—è¡¨
        batch_idx_list = []
        uni_label_temp = copy.deepcopy(self.uni_label_thermal)
        batch_num = int(self.N / (batchSize * num_pos)) + 1
        for _ in range(batch_num):
            batch_idx = []
            for _ in range(batchSize):
                if len(uni_label_temp) == 0:
                    uni_label_temp = copy.deepcopy(self.uni_label_thermal)
                idx = random.randint(0, len(uni_label_temp)-1)
                batch_idx.append(uni_label_temp[idx])
                uni_label_temp = np.delete(uni_label_temp, idx)
            batch_idx_list.append(np.array(batch_idx))

        # é¢„ç”Ÿæˆé‡‡æ ·ç´¢å¼•
        self.index1 = []  # å¯è§å…‰ç´¢å¼•
        self.index2 = []  # çº¢å¤–ç´¢å¼•
        color_pos_temp = copy.deepcopy(color_pos)
        thermal_pos_temp = copy.deepcopy(self.thermal_pos)
        for batch_idx in batch_idx_list:
            for pid in batch_idx:
                # é‡‡æ ·å¯è§å…‰æ ·æœ¬ï¼ˆå¾ªç¯å¤ç”¨ï¼‰
                if len(color_pos_temp[pid]) == 0:
                    color_pos_temp[pid] = copy.deepcopy(color_pos[pid])
                # é‡‡æ ·çº¢å¤–æ ·æœ¬ï¼ˆå¾ªç¯å¤ç”¨ï¼‰
                if len(thermal_pos_temp[pid]) == 0:
                    thermal_pos_temp[pid] = copy.deepcopy(self.thermal_pos[pid])
                
                sample_color = []
                sample_thermal = []
                for _ in range(num_pos):
                    # å¯è§å…‰é‡‡æ ·
                    c_idx = random.randint(0, len(color_pos_temp[pid])-1)
                    sample_color.append(color_pos_temp[pid][c_idx])
                    color_pos_temp[pid].pop(c_idx)
                    # çº¢å¤–é‡‡æ ·
                    t_idx = random.randint(0, len(thermal_pos_temp[pid])-1)
                    sample_thermal.append(thermal_pos_temp[pid][t_idx])
                    thermal_pos_temp[pid].pop(t_idx)
                
                self.index1.extend(sample_color)
                self.index2.extend(sample_thermal)
        
        # æˆªæ–­åˆ°æŒ‡å®šé•¿åº¦
        self.index1 = self.index1[:self.N]
        self.index2 = self.index2[:self.N]

    def __iter__(self):
        return iter(zip(self.index1, self.index2))

    def __len__(self):
        return self.N

# -------------------------- è¯¾ç¨‹å­¦ä¹ ä¸è®°å¿†åº“è¾…åŠ©å·¥å…· --------------------------
def generate_curriculum_mask(
    modal_pseudo_label: np.ndarray,
    tbgm_curriculum: list[tuple[int, int]],  # TBGMè¾“å‡ºï¼š(pid, level)ï¼Œlevel=0/1/2
    dataset_name: str = "sysu"
) -> np.ndarray:
    """
    ç”Ÿæˆå•æ¨¡æ€è¯¾ç¨‹æ©ç ï¼šä¸ºæ¯ä¸ªæ ·æœ¬åˆ†é…è¯¾ç¨‹çº§åˆ«ï¼ˆ0=plain,1=moderate,2=intricateï¼‰ğŸ”¶1-99ã€ğŸ”¶1-101
    Args:
        modal_pseudo_label: å•æ¨¡æ€ä¼ªæ ‡ç­¾
        tbgm_curriculum: TBGMæ¨¡å—çš„è¯¾ç¨‹åˆ’åˆ†ç»“æœ
    Returns:
        curriculum_mask: è¯¾ç¨‹æ©ç ï¼ˆé•¿åº¦=Nï¼Œå€¼ä¸º0/1/2ï¼‰
    """
    # æ„å»ºâ€œèº«ä»½-è¯¾ç¨‹çº§åˆ«â€æ˜ å°„
    pid2level = dict(tbgm_curriculum)
    # åˆå§‹åŒ–æ©ç ï¼ˆ-1è¡¨ç¤ºæœªåˆ†é…ï¼‰
    curriculum_mask = np.ones_like(modal_pseudo_label, dtype=int) * -1
    
    # ä¸ºæ¯ä¸ªæ ·æœ¬åˆ†é…è¯¾ç¨‹çº§åˆ«
    for idx, pid in enumerate(modal_pseudo_label):
        if pid in pid2level:
            curriculum_mask[idx] = pid2level[pid]
        else:
            # æœªåˆ’åˆ†çš„æ ·æœ¬å½’ä¸ºå¤æ‚è¯¾ç¨‹ï¼ˆè®ºæ–‡é»˜è®¤å¤„ç†ï¼‰
            curriculum_mask[idx] = 2
    
    # æ£€æŸ¥æœªåˆ†é…æ ·æœ¬
    unassigned_num = np.sum(curriculum_mask == -1)
    if unassigned_num > 0:
        print(f"è­¦å‘Šï¼š{unassigned_num}ä¸ªæ ·æœ¬æœªåˆ†é…è¯¾ç¨‹ï¼Œå·²å½’ä¸ºå¤æ‚è¯¾ç¨‹")
    
    return curriculum_mask


def get_current_curriculum(epoch: int, step_ii_total: int = CSANET_CONFIG["curriculum"]["step_ii_total"]) -> str:
    """
    æ ¹æ®Step-IIå½“å‰epochåˆ¤æ–­è¯¾ç¨‹é˜¶æ®µï¼ˆéµå¾ªè®ºæ–‡Algorithm 1ï¼‰ğŸ”¶1-210
    Args:
        epoch: Step-IIçš„å½“å‰epochï¼ˆ1-basedï¼‰
        step_ii_total: Step-IIæ€»epochæ•°
    Returns:
        current_stage: è¯¾ç¨‹é˜¶æ®µï¼ˆ"plain"/"moderate"/"intricate"ï¼‰
    """
    if not (1 <= epoch <= step_ii_total):
        raise ValueError(f"Step-II epochéœ€åœ¨1~{step_ii_total}ä¹‹é—´ï¼Œå½“å‰ä¸º{epoch}")
    
    stage1_end = int(step_ii_total * CSANET_CONFIG["curriculum"]["plain_ratio"])
    stage2_end = int(step_ii_total * CSANET_CONFIG["curriculum"]["moderate_ratio"])
    
    if epoch <= stage1_end:
        return "plain"
    elif epoch <= stage2_end:
        return "moderate"
    else:
        return "intricate"


def count_curriculum_anchors(
    curriculum_mask: np.ndarray,
    modal_pseudo_label: np.ndarray
) -> dict:
    """
    ç»Ÿè®¡å½“å‰è¯¾ç¨‹å„é˜¶æ®µçš„é”šç‚¹æ•°é‡ï¼ˆèº«ä»½æ•°+æ ·æœ¬æ•°ï¼‰ï¼Œé€‚é…è®ºæ–‡Fig.6(a)åˆ†æğŸ”¶1-265
    Args:
        curriculum_mask: è¯¾ç¨‹æ©ç 
        modal_pseudo_label: å•æ¨¡æ€ä¼ªæ ‡ç­¾
    Returns:
        anchor_stats: ç»Ÿè®¡ç»“æœï¼ˆå¦‚{"plain_pid_num": 50, "plain_sample_num": 500}ï¼‰
    """
    anchor_stats = defaultdict(int)
    level2name = {0: "plain", 1: "moderate", 2: "intricate"}
    
    for level, name in level2name.items():
        # ç­›é€‰è¯¥è¯¾ç¨‹çº§åˆ«çš„æ ·æœ¬
        level_mask = (curriculum_mask == level)
        level_pids = modal_pseudo_label[level_mask]
        # ç»Ÿè®¡èº«ä»½æ•°å’Œæ ·æœ¬æ•°
        anchor_stats[f"{name}_pid_num"] = len(np.unique(level_pids))
        anchor_stats[f"{name}_sample_num"] = np.sum(level_mask)
    
    return anchor_stats


def build_modal_memory(
    modal_feats: np.ndarray,
    modal_pseudo_label: np.ndarray,
    momentum: float = CSANET_CONFIG["memory"]["momentum"],
    old_memory: dict = None  # æ—§è®°å¿†åº“ï¼š{pid: centroid}
) -> tuple[np.ndarray, dict]:
    """
    æŒ‰è®ºæ–‡å…¬å¼3æ„å»º/æ›´æ–°å•æ¨¡æ€è®°å¿†åº“ï¼ˆèšç±»ä¸­å¿ƒï¼‰ï¼Œæ”¯æŒåŠ¨é‡æ›´æ–°ğŸ”¶1-132ã€ğŸ”¶1-134
    Args:
        modal_feats: å•æ¨¡æ€ç‰¹å¾ï¼ˆshape=[N, d]ï¼‰
        modal_pseudo_label: å•æ¨¡æ€ä¼ªæ ‡ç­¾ï¼ˆshape=[N]ï¼‰
        old_memory: æ—§è®°å¿†åº“ï¼ˆç”¨äºåŠ¨é‡æ›´æ–°ï¼ŒNoneåˆ™åˆå§‹åŒ–ï¼‰
    Returns:
        memory_array: è®°å¿†åº“æ•°ç»„ï¼ˆshape=[C, d]ï¼ŒCä¸ºèº«ä»½æ•°ï¼‰
        pid2idx: èº«ä»½åˆ°è®°å¿†åº“ç´¢å¼•çš„æ˜ å°„ï¼ˆdictï¼‰
    """
    # 1. è®¡ç®—å½“å‰èšç±»ä¸­å¿ƒï¼ˆå…¬å¼3ï¼‰
    pid2centroid = defaultdict(np.ndarray)
    pid_counter = Counter(modal_pseudo_label)
    
    for pid in pid_counter.keys():
        feats_pid = modal_feats[modal_pseudo_label == pid]
        centroid = np.mean(feats_pid, axis=0)  # èšç±»ä¸­å¿ƒ=ç‰¹å¾å¹³å‡å€¼
        pid2centroid[pid] = centroid
    
    # 2. åŠ¨é‡æ›´æ–°ï¼ˆè‹¥æœ‰æ—§è®°å¿†åº“ï¼‰
    if old_memory is not None:
        for pid in pid2centroid.keys():
            if pid in old_memory:
                # å…¬å¼ï¼šnew = momentum * old + (1 - momentum) * current
                pid2centroid[pid] = momentum * old_memory[pid] + (1 - momentum) * pid2centroid[pid]
        # ä¿ç•™æ—§è®°å¿†åº“ä¸­æœªå‡ºç°çš„èº«ä»½ï¼ˆé¿å…èº«ä»½ä¸¢å¤±ï¼‰
        for pid in old_memory.keys():
            if pid not in pid2centroid:
                pid2centroid[pid] = old_memory[pid]
    
    # 3. æ ¼å¼è½¬æ¢ï¼ˆæ’åºåè½¬ä¸ºæ•°ç»„ï¼‰
    valid_pids = sorted(pid2centroid.keys())
    memory_array = np.array([pid2centroid[pid] for pid in valid_pids])
    pid2idx = {pid: idx for idx, pid in enumerate(valid_pids)}
    
    return memory_array, pid2idx


def compute_prob_response(
    feats: torch.Tensor,
    memory: torch.Tensor,
    tau: float = CSANET_CONFIG["memory"]["tau"]
) -> torch.Tensor:
    """
    è®¡ç®—æ¦‚ç‡å“åº”ï¼ˆè®ºæ–‡å…¬å¼14ã€16ã€17ã€18ï¼‰ï¼Œç”¨äºIPCCæ¨¡å—ğŸ”¶1-187ã€ğŸ”¶1-193
    Args:
        feats: è¾“å…¥ç‰¹å¾ï¼ˆshape=[B, d]ï¼ŒBä¸ºbatch sizeï¼‰
        memory: å‚è€ƒè®°å¿†åº“ï¼ˆshape=[C, d]ï¼ŒCä¸ºèº«ä»½æ•°ï¼‰
        tau: æ¸©åº¦ç³»æ•°
    Returns:
        prob: æ¦‚ç‡å“åº”ï¼ˆshape=[B, C]ï¼Œæ¯è¡Œå’Œä¸º1ï¼‰
    """
    # è®¡ç®—ä½™å¼¦ç›¸ä¼¼åº¦ï¼ˆfeatsä¸memoryçš„ pairwise ç›¸ä¼¼åº¦ï¼‰
    sim = F.cosine_similarity(feats.unsqueeze(1), memory.unsqueeze(0), dim=-1)  # [B, C]
    # æ¸©åº¦ç¼©æ”¾+softmaxå½’ä¸€åŒ–
    prob = F.softmax(sim / tau, dim=1)
    return prob


def kl_div_consistency_loss(
    instance_prob: torch.Tensor,
    prototype_prob: torch.Tensor
) -> torch.Tensor:
    """
    è®¡ç®—IPCCæ¨¡å—çš„KLæ•£åº¦æŸå¤±ï¼ˆè®ºæ–‡å…¬å¼19ï¼‰ï¼Œå¼ºåˆ¶å®ä¾‹ä¸åŸå‹æ¦‚ç‡å“åº”ä¸€è‡´ğŸ”¶1-194
    Args:
        instance_prob: å¤æ‚å®ä¾‹çš„æ¦‚ç‡å“åº”ï¼ˆshape=[B, C]ï¼‰
        prototype_prob: å¯¹åº”åŸå‹çš„æ¦‚ç‡å“åº”ï¼ˆshape=[B, C]ï¼‰
    Returns:
        kl_loss: KLæ•£åº¦æŸå¤±ï¼ˆæ ‡é‡ï¼‰
    """
    # åŠ epsé¿å…log(0)
    eps = 1e-10
    kl_loss = F.kl_div(
        instance_prob.log() + eps,
        prototype_prob + eps,
        reduction="batchmean"  # æŒ‰batchå¹³å‡
    )
    return kl_loss

# -------------------------- å®éªŒè¯„ä¼°ä¸æ—¥å¿—å·¥å…· --------------------------
class AverageMeter(object):
    """
    å¹³å‡æŒ‡æ ‡è®¡ç®—å™¨ï¼šç”¨äºè·Ÿè¸ªè®­ç»ƒ/æµ‹è¯•è¿‡ç¨‹ä¸­çš„æŸå¤±ã€å‡†ç¡®ç‡ç­‰æŒ‡æ ‡ğŸ”¶1-212ã€ğŸ”¶1-223
    """
    def __init__(self):
        self.reset()

    def reset(self):
        self.val = 0.0    # å½“å‰å€¼
        self.avg = 0.0    # å¹³å‡å€¼
        self.sum = 0.0    # æ€»å’Œ
        self.count = 0    # è®¡æ•°

    def update(self, val: float, n: int = 1):
        self.val = val
        self.sum += val * n
        self.count += n
        self.avg = self.sum / self.count if self.count > 0 else 0.0


def compute_ari_score(
    true_label: np.ndarray,  # ä¿®æ­£ï¼šå¼ºåˆ¶è¦æ±‚è¾“å…¥çœŸå®æ ‡ç­¾ï¼ˆè®ºæ–‡ğŸ”¶1-256éœ€åŸºäºçœŸå®æ ‡ç­¾è¯„ä¼°ï¼‰
    pseudo_label: np.ndarray,
    modal: str = "vis"
) -> float:
    """
    è®¡ç®—Adjusted Rand Indexï¼ˆARIï¼‰ï¼Œè¯„ä¼°ä¼ªæ ‡ç­¾ä¸çœŸå®æ ‡ç­¾çš„èšç±»ä¸€è‡´æ€§ï¼ˆè®ºæ–‡è¡¨VIIIï¼‰ğŸ”¶1-256
    è®ºæ–‡ä¸­ç”¨äºè¡¡é‡å¯è§å…‰ï¼ˆVISï¼‰ã€çº¢å¤–ï¼ˆIRï¼‰æ¨¡æ€ä¼ªæ ‡ç­¾çš„å¯é æ€§ï¼Œå€¼è¶Šé«˜èšç±»è´¨é‡è¶Šå¥½ã€‚
    
    Args:
        true_label: æ¨¡æ€çœŸå®æ ‡ç­¾ï¼ˆnp.ndarrayï¼Œshape=[N]ï¼‰ï¼Œéœ€ä¸æ•°æ®é›†çœŸå®èº«ä»½å¯¹åº”ï¼ˆå¦‚SYSU-MM01æµ‹è¯•é›†96ä¸ªèº«ä»½ï¼‰ğŸ”¶1-204
        pseudo_label: æ¨¡æ€ä¼ªæ ‡ç­¾ï¼ˆnp.ndarrayï¼Œshape=[N]ï¼‰ï¼Œç”±DBSCANèšç±»ç”Ÿæˆï¼ˆğŸ”¶1-131ï¼‰
        modal: æ¨¡æ€æ ‡è¯†ï¼ˆä»…æ”¯æŒ"vis"=å¯è§å…‰ã€"ir"=çº¢å¤–ï¼‰ï¼ŒåŒ¹é…è®ºæ–‡åŒæ¨¡æ€è®¾å®šğŸ”¶1-88
    
    Returns:
        ari: ARIåˆ†æ•°ï¼ˆèŒƒå›´[-1,1]ï¼Œ1è¡¨ç¤ºå®Œå…¨ä¸€è‡´ï¼Œ0è¡¨ç¤ºéšæœºèšç±»ï¼‰
    
    Raises:
        ValueError: è‹¥å‚æ•°ä¸æ»¡è¶³è®ºæ–‡è®¾å®šï¼ˆå¦‚æ ‡ç­¾é•¿åº¦ä¸åŒ¹é…ã€æ¨¡æ€æ ‡è¯†é”™è¯¯ï¼‰
    """
    # 1. æ ¡éªŒæ¨¡æ€æ ‡è¯†ï¼ˆä»…æ”¯æŒè®ºæ–‡ä¸­çš„åŒæ¨¡æ€ï¼‰ğŸ”¶1-88
    if modal not in ["vis", "ir"]:
        raise ValueError(
            f"æ¨¡æ€æ ‡è¯†é”™è¯¯ï¼š{modal}ï¼Œä»…æ”¯æŒ'vis'ï¼ˆå¯è§å…‰ï¼‰æˆ–'ir'ï¼ˆçº¢å¤–ï¼‰"
            "ï¼ˆå‚è€ƒè®ºæ–‡ğŸ”¶1-88ï¼ŒVI-ReIDä»…æ¶‰åŠå¯è§å…‰-çº¢å¤–åŒæ¨¡æ€ï¼‰"
        )
    
    # 2. æ ¡éªŒæ ‡ç­¾æ•°ç»„éç©º
    if len(true_label) == 0 or len(pseudo_label) == 0:
        raise ValueError(
            "çœŸå®æ ‡ç­¾/ä¼ªæ ‡ç­¾ä¸ºç©ºæ•°ç»„ï¼Œæ— æ³•è®¡ç®—ARI"
            "ï¼ˆå‚è€ƒè®ºæ–‡ğŸ”¶1-256ï¼Œéœ€è¾“å…¥æœ‰æ•ˆæ ·æœ¬çš„æ ‡ç­¾ï¼‰"
        )
    
    # 3. æ ¡éªŒçœŸå®æ ‡ç­¾ä¸ä¼ªæ ‡ç­¾é•¿åº¦ä¸€è‡´ï¼ˆè®ºæ–‡è¦æ±‚ä¸€ä¸€å¯¹åº”ï¼‰ğŸ”¶1-256
    if len(true_label) != len(pseudo_label):
        raise ValueError(
            f"çœŸå®æ ‡ç­¾ä¸ä¼ªæ ‡ç­¾é•¿åº¦ä¸åŒ¹é…ï¼š{len(true_label)} vs {len(pseudo_label)}"
            "ï¼ˆå‚è€ƒè®ºæ–‡ğŸ”¶1-256ï¼ŒåŒä¸€æ¨¡æ€çš„çœŸå®æ ‡ç­¾ä¸ä¼ªæ ‡ç­¾éœ€è¦†ç›–ç›¸åŒæ ·æœ¬ï¼‰"
        )
    
    # 4. è®¡ç®—ARIï¼ˆä¸¥æ ¼éµå¾ªè®ºæ–‡è¡¨VIIIçš„è¯„ä¼°é€»è¾‘ï¼‰ğŸ”¶1-256
    try:
        ari = adjusted_rand_score(true_label, pseudo_label)
    except Exception as e:
        raise RuntimeError(
            f"ARIè®¡ç®—å¤±è´¥ï¼š{str(e)}"
            "ï¼ˆæ£€æŸ¥æ ‡ç­¾æ ¼å¼ï¼šéœ€ä¸ºæ•´æ•°æ•°ç»„ï¼Œå¦‚çœŸå®æ ‡ç­¾[0,0,1,1]ã€ä¼ªæ ‡ç­¾[1,1,0,0]ï¼‰"
        )
    
    # 5. æ‰“å°ä¸è®ºæ–‡ä¸€è‡´çš„æ¨¡æ€æ ‡è¯†ï¼ˆå¦‚"VIS-ARI" "IR-ARI"ï¼‰ğŸ”¶1-256
    modal_name = "VIS" if modal == "vis" else "IR"
    print(f"{modal_name}-ARIåˆ†æ•°ï¼š{ari:.4f}ï¼ˆå‚è€ƒè®ºæ–‡è¡¨VIIIï¼Œå€¼è¶Šé«˜èšç±»è´¨é‡è¶Šå¥½ï¼‰")
    
    return ari


class CSANetLogger(object):
    """
    CSANetä¸“ç”¨æ—¥å¿—å·¥å…·ï¼šè®°å½•è¯¾ç¨‹é˜¶æ®µã€æŒ‡æ ‡å˜åŒ–ã€é”šç‚¹æ•°é‡ç­‰å…³é”®ä¿¡æ¯ğŸ”¶1-265ã€ğŸ”¶1-267
    """
    def __init__(self, fpath: str = None):
        self.console = sys.stdout
        self.file = None
        if fpath is not None:
            mkdir_if_missing(os.path.dirname(fpath))
            self.file = open(fpath, 'w', encoding='utf-8')

    def __del__(self):
        self.close()

    def __enter__(self):
        pass

    def __exit__(self, *args):
        self.close()

    def write(self, msg: str):
        self.console.write(msg)
        if self.file is not None:
            self.file.write(msg)

    def flush(self):
        self.console.flush()
        if self.file is not None:
            self.file.flush()
            os.fsync(self.file.fileno())

    def close(self):
        self.console.close()
        if self.file is not None:
            self.file.close()

    def log_curriculum(self, epoch: int, step: str, stats: dict):
        """è®°å½•è¯¾ç¨‹é˜¶æ®µç»Ÿè®¡ä¿¡æ¯ï¼ˆé”šç‚¹æ•°é‡ç­‰ï¼‰"""
        msg = f"[{step}] Epoch {epoch:3d} | è¯¾ç¨‹ç»Ÿè®¡ï¼š"
        for k, v in stats.items():
            msg += f"{k}={v:4d} | "
        msg += "\n"
        self.write(msg)
        self.flush()

    def log_metrics(self, epoch: int, step: str, metrics: dict):
        """è®°å½•è¯„ä¼°æŒ‡æ ‡ï¼ˆRank-1ã€mAPç­‰ï¼‰"""
        msg = f"[{step}] Epoch {epoch:3d} | è¯„ä¼°æŒ‡æ ‡ï¼š"
        for k, v in metrics.items():
            msg += f"{k}={v:.4f} | "
        msg += "\n"
        self.write(msg)
        self.flush()

    def log_loss(self, epoch: int, step: str, losses: dict):
        """è®°å½•æŸå¤±å˜åŒ–"""
        msg = f"[{step}] Epoch {epoch:3d} | æŸå¤±ï¼š"
        for k, v in losses.items():
            msg += f"{k}={v:.4f} | "
        msg += "\n"
        self.write(msg)
        self.flush()

# -------------------------- é€šç”¨å·¥å…·å‡½æ•° --------------------------
def mkdir_if_missing(directory: str):
    """åˆ›å»ºç›®å½•ï¼ˆè‹¥ä¸å­˜åœ¨ï¼‰"""
    if not os.path.exists(directory):
        try:
            os.makedirs(directory)
        except OSError as e:
            if e.errno != errno.EEXIST:
                raise


def set_seed(seed: int, cuda: bool = True):
    """
    ä¸¥æ ¼è®¾ç½®éšæœºç§å­ï¼Œç¡®ä¿å®éªŒå¯å¤ç°ï¼ˆè¦†ç›–numpyã€torchã€CUDAï¼‰ğŸ”¶1-204ã€ğŸ”¶1-205
    Args:
        seed: éšæœºç§å­
        cuda: æ˜¯å¦ä½¿ç”¨CUDA
    """
    random.seed(seed)
    np.random.seed(seed)
    torch.manual_seed(seed)
    if cuda:
        torch.cuda.manual_seed(seed)
        torch.cuda.manual_seed_all(seed)
        # ç¦ç”¨cuDNNè‡ªåŠ¨ä¼˜åŒ–ï¼ˆé¿å…ç›¸åŒç§å­ä¸‹ç»“æœå·®å¼‚ï¼‰
        torch.backends.cudnn.deterministic = True
        torch.backends.cudnn.benchmark = False
    print(f"å·²è®¾ç½®éšæœºç§å­ï¼š{seed}ï¼ˆCUDA={cuda}ï¼‰")


def sort_list_with_unique_index(initial_list: list) -> tuple[np.ndarray, np.ndarray, np.ndarray, np.ndarray, dict]:
    """
    æ’åºå¹¶è·å–æ¯ä¸ªå”¯ä¸€å€¼çš„é¦–å°¾ç´¢å¼•ä¸æ•°é‡ï¼Œé€‚é…æ ·æœ¬åˆ†ç»„ç»Ÿè®¡ğŸ”¶1-256
    Returns:
        s1: æ¯ä¸ªå”¯ä¸€å€¼çš„é¦–ç´¢å¼•
        s2: æ¯ä¸ªå”¯ä¸€å€¼çš„å°¾ç´¢å¼•
        num: æ¯ä¸ªå”¯ä¸€å€¼çš„æ•°é‡
        idx_: æ’åºåçš„å”¯ä¸€å€¼
        s3: æ¯ä¸ªå”¯ä¸€å€¼çš„æ‰€æœ‰ç´¢å¼•
    """
    a = np.asarray(initial_list)
    if len(a) == 0:
        return np.array([]), np.array([]), np.array([]), np.array([]), defaultdict(list)
    
    # è·å–å”¯ä¸€å€¼åŠå…¶é¦–æ¬¡å‡ºç°ç´¢å¼•
    a_u, idx = np.unique(a, return_index=True)
    idx_sorted = np.sort(idx)
    idx_ = a[idx_sorted]  # æ’åºåçš„å”¯ä¸€å€¼
    
    # åˆå§‹åŒ–ç»Ÿè®¡æ•°ç»„
    max_val = a_u[-1]
    s1 = np.ones(max_val + 1, dtype=int) * -1  # é¦–ç´¢å¼•
    s2 = np.ones(max_val + 1, dtype=int) * -1  # å°¾ç´¢å¼•
    num = np.zeros(max_val + 1, dtype=int)     # æ•°é‡
    s3 = defaultdict(list)                     # æ‰€æœ‰ç´¢å¼•
    
    # éå†ç»Ÿè®¡
    for i, val in enumerate(a):
        if val not in a_u:
            continue
        if s1[val] == -1:
            s1[val] = i
            s2[val] = i
            num[val] = 1
        else:
            s2[val] = i
            num[val] += 1
        s3[val].append(i)
    
    # ç­›é€‰æœ‰æ•ˆå”¯ä¸€å€¼çš„ç»Ÿè®¡ç»“æœ
    s1 = s1[idx_]
    s2 = s2[idx_]
    num = num[idx_]
    
    return s1, s2, num, idx_, s3


def validate_image_path(img_paths: list[str]) -> list[str]:
    """
    éªŒè¯å›¾åƒè·¯å¾„æœ‰æ•ˆæ€§ï¼ˆå­˜åœ¨ä¸”å¯æ‰“å¼€ï¼‰ï¼Œé€‚é…æµ‹è¯•é›†å¼‚å¸¸å›¾åƒè¿‡æ»¤ğŸ”¶1-204ã€ğŸ”¶1-205
    Args:
        img_paths: å›¾åƒè·¯å¾„åˆ—è¡¨
    Returns:
        valid_paths: æœ‰æ•ˆè·¯å¾„åˆ—è¡¨
    """
    valid_paths = []
    for path in img_paths:
        if not os.path.exists(path):
            print(f"è­¦å‘Šï¼šå›¾åƒä¸å­˜åœ¨ï¼Œè·³è¿‡ï¼š{path}")
            continue
        try:
            with Image.open(path) as img:
                img.verify()  # éªŒè¯å›¾åƒå®Œæ•´æ€§
            valid_paths.append(path)
        except (IOError, SyntaxError) as e:
            print(f"è­¦å‘Šï¼šå›¾åƒæŸåï¼Œè·³è¿‡ï¼š{path}ï¼Œé”™è¯¯ï¼š{e}")
    return valid_paths